{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis of Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Review Amazon 8-8-2019 Training(Apr2016 to July2018).csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Product Review URL</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Verified Review</th>\n",
       "      <th>Variation ASIN</th>\n",
       "      <th>Sku</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B074N7C482</td>\n",
       "      <td>Modern Outdoor Garden, Patio 4 Piece Seat - Wi...</td>\n",
       "      <td>https://www.amazon.com/gp/review/R3CU4J2FU1FH1C</td>\n",
       "      <td>3</td>\n",
       "      <td>12/31/2017</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>Installed and not used yet as winter sets in, ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>B074N7WYNV</td>\n",
       "      <td>RTN25-BLK-RED</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01G67EUJW</td>\n",
       "      <td>Divano Roma Furniture Collection - Modern Two ...</td>\n",
       "      <td>https://www.amazon.com/gp/review/R2QAY39ZRHH7PP</td>\n",
       "      <td>1</td>\n",
       "      <td>12/31/2017</td>\n",
       "      <td>One Star</td>\n",
       "      <td>Cheap quality. Okay for staging</td>\n",
       "      <td>Yes</td>\n",
       "      <td>B01G67EUJM</td>\n",
       "      <td>EXP40-SM-VV-BG</td>\n",
       "      <td>Beige</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B018YEC3HG</td>\n",
       "      <td>Deluxe Espresso Brown Bonded Leather Platform ...</td>\n",
       "      <td>https://www.amazon.com/gp/review/RKWZ16GUYSJ2B</td>\n",
       "      <td>1</td>\n",
       "      <td>12/31/2017</td>\n",
       "      <td>A complete waste of our hard earned money</td>\n",
       "      <td>Do Not Buy!! You will constantly need to tight...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>B018YEC3Z8</td>\n",
       "      <td>BDS-02-EX-QUEEN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B074N7C482</td>\n",
       "      <td>Modern Outdoor Garden, Patio 4 Piece Seat - Wi...</td>\n",
       "      <td>https://www.amazon.com/gp/review/R2E4HYVPYYSO4V</td>\n",
       "      <td>5</td>\n",
       "      <td>12/30/2017</td>\n",
       "      <td>Nice set!</td>\n",
       "      <td>I gave it to my parents as a Christmas gift fo...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>B074N7C482</td>\n",
       "      <td>RTN25-BR-BG</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B01M1HGYIK</td>\n",
       "      <td>Modern Tufted Fabric Living Room Armchair (Lig...</td>\n",
       "      <td>https://www.amazon.com/gp/review/R1NSQLVE9NS6RS</td>\n",
       "      <td>5</td>\n",
       "      <td>12/30/2017</td>\n",
       "      <td>Love these chairs/Great price</td>\n",
       "      <td>I really like these chairs. I had never purcha...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>B01LZV1RCP</td>\n",
       "      <td>ARM(M)02-FB-1S-GR</td>\n",
       "      <td>Light Grey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN                                      Product Title  \\\n",
       "0  B074N7C482  Modern Outdoor Garden, Patio 4 Piece Seat - Wi...   \n",
       "1  B01G67EUJW  Divano Roma Furniture Collection - Modern Two ...   \n",
       "2  B018YEC3HG  Deluxe Espresso Brown Bonded Leather Platform ...   \n",
       "3  B074N7C482  Modern Outdoor Garden, Patio 4 Piece Seat - Wi...   \n",
       "4  B01M1HGYIK  Modern Tufted Fabric Living Room Armchair (Lig...   \n",
       "\n",
       "                                Product Review URL  Review Rating Review Date  \\\n",
       "0  https://www.amazon.com/gp/review/R3CU4J2FU1FH1C              3  12/31/2017   \n",
       "1  https://www.amazon.com/gp/review/R2QAY39ZRHH7PP              1  12/31/2017   \n",
       "2   https://www.amazon.com/gp/review/RKWZ16GUYSJ2B              1  12/31/2017   \n",
       "3  https://www.amazon.com/gp/review/R2E4HYVPYYSO4V              5  12/30/2017   \n",
       "4  https://www.amazon.com/gp/review/R1NSQLVE9NS6RS              5  12/30/2017   \n",
       "\n",
       "                                Review Title  \\\n",
       "0                                Three Stars   \n",
       "1                                   One Star   \n",
       "2  A complete waste of our hard earned money   \n",
       "3                                  Nice set!   \n",
       "4              Love these chairs/Great price   \n",
       "\n",
       "                                         Review Text Verified Review  \\\n",
       "0  Installed and not used yet as winter sets in, ...             Yes   \n",
       "1                    Cheap quality. Okay for staging             Yes   \n",
       "2  Do Not Buy!! You will constantly need to tight...             Yes   \n",
       "3  I gave it to my parents as a Christmas gift fo...             Yes   \n",
       "4  I really like these chairs. I had never purcha...             Yes   \n",
       "\n",
       "  Variation ASIN                Sku       Color  \n",
       "0     B074N7WYNV      RTN25-BLK-RED       Black  \n",
       "1     B01G67EUJM     EXP40-SM-VV-BG       Beige  \n",
       "2     B018YEC3Z8    BDS-02-EX-QUEEN         NaN  \n",
       "3     B074N7C482        RTN25-BR-BG       Brown  \n",
       "4     B01LZV1RCP  ARM(M)02-FB-1S-GR  Light Grey  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.iloc[:, [3, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Installed and not used yet as winter sets in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cheap quality. Okay for staging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Do Not Buy!! You will constantly need to tight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>I gave it to my parents as a Christmas gift fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I really like these chairs. I had never purcha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review Rating                                        Review Text\n",
       "0              3  Installed and not used yet as winter sets in, ...\n",
       "1              1                    Cheap quality. Okay for staging\n",
       "2              1  Do Not Buy!! You will constantly need to tight...\n",
       "3              5  I gave it to my parents as a Christmas gift fo...\n",
       "4              5  I really like these chairs. I had never purcha..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6013 entries, 0 to 6012\n",
      "Data columns (total 2 columns):\n",
      "Review Rating    6013 non-null int64\n",
      "Review Text      6013 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 94.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.696325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.516788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review Rating\n",
       "count    6013.000000\n",
       "mean        3.696325\n",
       "std         1.516788\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         5.000000\n",
       "max         5.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Encoding the rating 4,5 stars to 2 (good), 1,2,3 stars to 0 (bad)\n",
    "for i in range(0, df.shape[0]):\n",
    "    if df.at[i,'Review Rating'] > 3:\n",
    "        df.at[i,'Score'] = 1\n",
    "    elif df.at[i,'Review Rating'] < 4:\n",
    "        df.at[i,'Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Review Rating'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Installed and not used yet as winter sets in, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheap quality. Okay for staging</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do Not Buy!! You will constantly need to tight...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I gave it to my parents as a Christmas gift fo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really like these chairs. I had never purcha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Score\n",
       "0  Installed and not used yet as winter sets in, ...    0.0\n",
       "1                    Cheap quality. Okay for staging    0.0\n",
       "2  Do Not Buy!! You will constantly need to tight...    0.0\n",
       "3  I gave it to my parents as a Christmas gift fo...    1.0\n",
       "4  I really like these chairs. I had never purcha...    1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [(\"I don't like this sofa !\", 0), (\"I really don't love it.\", 0), (\"I don't like the color as it does not match the description.\", 0),\n",
    "        (\"I don't like the material.\", 0), (\"I don't love the material.\", 0),(\"I don't love the color as it does not match the description.\", 0),\n",
    "        (\"I don't love this sofa !\", 0)]\n",
    "df2 = pd.DataFrame(lines, columns = ['Review Text' , 'Score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df2,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c481a90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df['Score'],label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Review Text': 'Review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     I gave it to my parents as a Christmas gift fo...\n",
       "4     I really like these chairs. I had never purcha...\n",
       "5                We really enjoy it has many many uses.\n",
       "6     Looks pretty. Bought it for my waiting room at...\n",
       "8     Nice chair and works fine but with a short bac...\n",
       "9                 My mom loves the chair.  Comfortable.\n",
       "10    Very nice stylish sofa !\\nEasy to install and ...\n",
       "12                                            ez set up\n",
       "13    The couch is nice and was fairly easy to put t...\n",
       "15    I gave this 4 stars because and YES, I do know...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Score']==1]['Review'][:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Installed and not used yet as winter sets in, ...\n",
       "1                       Cheap quality. Okay for staging\n",
       "2     Do Not Buy!! You will constantly need to tight...\n",
       "7     The price was right, shipping was prompt.\\nHad...\n",
       "11                    Uncomfortable but nice to look at\n",
       "14    Poor quality futon. It's extremely uncomfortab...\n",
       "24    I am/was extremely disappointed with this item...\n",
       "28    DON'T BUY IT !!!!!!!!!!\\nWhen you get everythi...\n",
       "31    Received this with the back of the couch broke...\n",
       "33    No instructions, missing parts, missing slots ...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Score']==0]['Review'][:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_w = ['aren',\"aren't\",\"couldn'\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'don',\"don't\",\"hadn't\",'hasn',\n",
    "       \"hasn't\",'isn',\"isn't\",'mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'no','nor','not',\"shan't\",'shouldn',\n",
    "       \"shouldn't\",'wasn',\"wasn't\",\"won't\",'wouldn',\"wouldn't\"]\n",
    "for i in l_w:\n",
    "    stop_words.discard(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'd', 'did', 'do', 'does', 'doing', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', 'has', 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'more', 'most', 'my', 'myself', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', 'she', \"she's\", 'should', \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Score'], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,ngram_range = (1,3),tokenizer = token.tokenize, max_features = 10000)\n",
    "cv.fit(df['Review'])\n",
    "xtrain_count = cv.transform(X_train)\n",
    "xtest_count = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=20000,stop_words=stop_words)\n",
    "tfidf_vect.fit(df['Review'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=20000,\n",
    "                                  stop_words=stop_words)\n",
    "tfidf_vect_ngram.fit(df['Review'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=20000,\n",
    "                                        stop_words=stop_words)\n",
    "tfidf_vect_ngram_chars.fit(df['Review'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_train) \n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "#from keras.preprocessing import text, sequence\n",
    "#embeddings_index = {}\n",
    "#for i, line in enumerate(open('wiki-news-300d-1M.vec')):\n",
    "#    values = line.split()\n",
    "#    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "# \n",
    "# create a tokenizer \n",
    "#token = text.Tokenizer()\n",
    "#token.fit_on_texts(df['Review'])\n",
    "#word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "#train_seq_x = sequence.pad_sequences(token.texts_to_sequences(X_train), maxlen=70)\n",
    "#test_seq_x = sequence.pad_sequences(token.texts_to_sequences(X_test), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "#embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "#for word, i in word_index.items():\n",
    "#    embedding_vector = embeddings_index.get(word)\n",
    "#    if embedding_vector is not None:\n",
    "#        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)  \n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_count, y_train, xtest_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(LogisticRegression(), xtrain_count, y_train, xtest_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(LogisticRegression(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(LogisticRegression(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(LogisticRegression(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on Count Vectors\n",
    "accuracy = train_model(LinearSVC(), xtrain_count, y_train, xtest_count)\n",
    "print(\"SVM, Count Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Word Level TF IDF Vectors\n",
    "accuracy = train_model(LinearSVC(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"SVM, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(LinearSVC(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "accuracy = train_model(LinearSVC(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars)\n",
    "print(\"SVM, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randon Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randon Forest on Count Vectors\n",
    "accuracy = train_model(RandomForestClassifier(), xtrain_count, y_train, xtest_count)\n",
    "print(\"Randon Forest, Count Vectors: \", accuracy)\n",
    "\n",
    "# Randon Forest on Word Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"Randon Forest, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Randon Forest on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"Randon Forest, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Randon Forest on Character Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars)\n",
    "print(\"Randon Forest, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    print (\"Currently fitting: {}\".format(model_name))\n",
    "    accuracies = cross_val_score(model, xtrain_tfidf_ngram, y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy of LinearSVC =\", cv_df.iloc[[5,6,7,8,9], 2].mean())\n",
    "print(\"Mean accuracy of LogisticRegression =\", cv_df.iloc[[15,16,17,18,19], 2].mean())\n",
    "print(\"Mean accuracy of MultinomialNB =\", cv_df.iloc[[10,11,12,13,14], 2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import layers, models, optimizers\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#classifier1 = Sequential()\n",
    "#classifier1.add(Dense(units=36, activation=\"relu\", input_dim=xtrain_tfidf_ngram.shape[1]))\n",
    "#classifier1.add(Dense(units=36, activation=\"relu\"))\n",
    "#classifier1.add(Dense(units=3, activation=\"softmax\"))\n",
    "#classifier1.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#classifier1.fit(xtrain_tfidf_ngram, y_train_dummy, batch_size=10, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "svm = LinearSVC()\n",
    "svm.fit(xtrain_tfidf_ngram, y_train)\n",
    "svm_y_pred = svm.predict(xtest_tfidf_ngram)\n",
    "svm_cm = metrics.confusion_matrix(y_test, svm_y_pred, [0,1])\n",
    "score = svm.score(xtest_tfidf_ngram, y_test)\n",
    "sns.heatmap(svm_cm, annot=True)\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('LinearSVC')\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "print(\"The accuracy score is:\", score, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(classifier, feature_names, top_features=50):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficients(svm, tfidf_vect_ngram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(a_list):\n",
    "    half = len(a_list)//2\n",
    "    return a_list[:half], a_list[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_power_words (classifier, tfidf, nb_words):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-nb_words:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:nb_words]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "    feature_names = np.array(feature_names)\n",
    "    coeff = np.arange(1, 1 + 2 * nb_words)\n",
    "    top_feature_names = feature_names[top_coefficients]\n",
    "    top_negative_feature_names,top_positive_feature_names = split_list(top_feature_names)\n",
    "    return print(\"Top 50 positives words: \",top_positive_feature_names, \n",
    "                 \"\\n \\n Top 50 negatives words: \",top_negative_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_power_words (svm, tfidf_vect_ngram, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common word using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ML = pd.read_excel('Test (EXP54).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = dataset_ML.iloc[:, [3, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, df_ML.shape[0]):\n",
    "    if df_ML.at[i,'Review Rating'] > 3:\n",
    "        df_ML.at[i,'Score'] = 1\n",
    "    elif df_ML.at[i,'Review Rating'] < 4:\n",
    "        df_ML.at[i,'Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df_ML.drop(['Review Rating'], axis = 1)\n",
    "df_ML.rename(columns={'Review Text': 'Review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_ML = df_ML.iloc[:,0]\n",
    "y_df_ML = df_ML.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_ML_tfidf = tfidf_vect_ngram.transform(X_df_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_ML_pred = svm.predict(X_df_ML_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_df_ML, y_df_ML_pred)\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\"Small but good extra sleeper for the price\"]\n",
    "d_tfidf = tfidf_vect_ngram.transform(d)\n",
    "d_pred = svm.predict(d_tfidf)\n",
    "d_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_ML_pred = pd.DataFrame(y_df_ML_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred = pd.concat([X_df_ML, y_df_ML_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred.rename(columns={0: 'Score'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred_bad = df_ML_pred.loc[df_ML_pred['Score'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred_bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred_good = df_ML_pred.loc[df_ML_pred['Score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_pred_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews_ML = ''\n",
    "for x in df_ML_pred_bad['Review']:\n",
    "    bad_reviews_ML = bad_reviews_ML + str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews_ML = ''\n",
    "for i in df_ML_pred_good['Review']:\n",
    "    good_reviews_ML = good_reviews_ML + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "from nltk import everygrams\n",
    "from collections import Counter\n",
    "\n",
    "def count_words(s, n_gram_min, n_gram_max, nb_words):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    filtered_sentence = [] \n",
    "    for w in tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    output = list(everygrams(filtered_sentence, n_gram_min, n_gram_max))\n",
    "    c = Counter(output)\n",
    "    counts = c.most_common(nb_words)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_2_words_reviews_ML = count_words(bad_reviews_ML, 2, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_3_words_reviews_ML = count_words(bad_reviews_ML, 3, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_2_words_reviews_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_3_words_reviews_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "pickle.dump(svm, open(\"/Users/DG/Desktop/SOFAMANIA/model_svm.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common word whithout ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('EXP02.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.iloc[:, [3, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, df.shape[0]):\n",
    "    if df.at[i,'Review Rating'] > 3:\n",
    "        df.at[i,'Score'] = 1\n",
    "    elif df.at[i,'Review Rating'] < 4:\n",
    "        df.at[i,'Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Review Rating'], axis = 1)\n",
    "df.rename(columns={'Review Text': 'Review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = df.loc[df['Score'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = df.loc[df['Score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews = ''\n",
    "for x in df_bad['Review']:\n",
    "    bad_reviews = bad_reviews + str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews = ''\n",
    "for i in df_good['Review']:\n",
    "    good_reviews = good_reviews + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_2_words_reviews = count_words(bad_reviews, 2, 2, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_3_words_reviews = count_words(bad_reviews, 3, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_2_words_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bad_3_words_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_good_2_words_reviews = count_words(good_reviews, 2, 2, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_good_3_words_reviews = count_words(good_reviews, 3, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_good_2_words_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_good_3_words_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
